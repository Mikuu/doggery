AI
--

# Hugging Face
![ai-hugging-face](images/ai.hugging-face.png)
Hugging faceæ˜¯å½“å‰æœ€å¤§çš„AIæ¨¡å‹èµ„æºåº“ï¼Œç±»ä¼¼äºï¼š
- githubæ˜¯æœ€å¤§ä»£ç èµ„æºåº“
- dockerhubæ˜¯æœ€å¤§çš„æ™¯è±¡èµ„æºåº“

Hugging faceé‡Œé¢å…±äº«çš„AIæ¨¡å‹ä¸ä»…ä»…æ˜¯å¤§è¯­è¨€æ¨¡å‹(Large Language Model)ï¼Œè¿˜è¦å…¶ä»–çš„æ¨¡å‹ï¼Œæ¯”å¦‚æ–‡ç”Ÿå›¾çš„æ¨¡å‹ã€æ–‡ç”Ÿè§†é¢‘çš„æ¨¡å‹ã€å›¾åƒè¯†åˆ«çš„æ¨¡å‹ã€æœºå™¨è§†è§‰çš„æ¨¡å‹ç­‰ç­‰ã€‚

æ¯”å¦‚ï¼Œä»¥ä¸‹å°±æ˜¯æœ€æ–°çš„Deepseek-v3.1çš„æ¨¡å‹ï¼š
![ai-model-deepseek](images/ai.model-deepseek-v3.1.png)

# Ollama
![ai-ollama](images/ai.ollama.png)
Ollamaæ˜¯ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œå¯ä»¥ä¸‹è½½å’Œç®¡ç†å¸¸è§çš„AIæ¨¡å‹ï¼Œå¹¶ä¸”åœ¨æœ¬åœ°å¿«é€Ÿå¯åŠ¨ã€‚Ollamaçš„åŠŸèƒ½éå¸¸ç±»ä¼¼äºDocker.

## AIæ¨¡å‹
AIæ¨¡å‹çš„ä½¿ç”¨ç®€å•æ¥è¯´åŒ…å«äº†ä¸‰å±‚ï¼š
- `æ¨¡å‹æœ¬èº«`ï¼Œåªæ˜¯åŒ…å«äº†çŸ¥è¯†ä¸ä¿¡æ¯çš„æ–‡ä»¶ï¼Œå¦‚ .bin, .safetensors, .pt ç­‰æ–‡ä»¶ï¼Œæ¨¡å‹æ–‡ä»¶æ˜¯ä¸èƒ½ç›´æ¥è¿è¡Œçš„ï¼Œ
- `æ‰§è¡Œæ¡†æ¶`ï¼Œä¹Ÿå«å­¦ä¹ æ¡†æ¶ã€æ¨ç†æ¡†æ¶ï¼Œæ¯”å¦‚transformer, PyTorch, Tensorflow, llama.cppç­‰ç­‰ï¼Œè¿™äº›æ¡†æ¶èƒ½å¤ŸåŠ è½½æ¨¡å‹æ–‡ä»¶ï¼Œè¿›è¡Œæ¨ç†æ¼”ç®—å¹¶è¿”å›ç»“è®ºã€‚è¿™äº›æ¡†æ¶æœ¬èº«ä¹Ÿå°±æ˜¯å„ç§åº“å‡½æ•°ï¼Œæ¯”å¦‚pythonçš„å„ç§åº“æ–‡ä»¶ï¼Œ
```python
# 1. ä½¿ç”¨ Ollama (æœ€ç®€å•)
import requests
response = requests.post("http://localhost:11434/api/generate", 
                        json={"model": "deepseek-coder", "prompt": "ä½ å¥½"})

# 2. ä½¿ç”¨ Transformers (å¾ˆå¸¸ç”¨)
from transformers import AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained("/path/to/deepseek-model")

# 3. ä½¿ç”¨ llama.cpp (é«˜æ€§èƒ½)
from llama_cpp import Llama
llm = Llama(model_path="deepseek-model.gguf")

# 4. ä½¿ç”¨ PyTorch (æœ€åº•å±‚)
import torch
model = torch.load("deepseek-model.pth")
# ... è¿˜éœ€è¦è‡ªå·±å®ç°tokenizationã€æ¨ç†é€»è¾‘ç­‰
```
- `äººæœºäº¤äº’`ï¼Œä½¿ç”¨æ¡†æ¶åŠ è½½æ¨¡å‹çš„è¿‡ç¨‹å°±æ˜¯`éƒ¨ç½²`,æ¨¡å‹éƒ¨ç½²å®Œæˆä¹‹åï¼Œéœ€è¦å’Œäººè¿›è¡Œäº¤äº’ï¼Œè¿™å°±æ˜¯å„ç§AIäº§å“ï¼Œæ¯”å¦‚Chatgptå’ŒDeepseekçš„ç½‘ç«™å’ŒAPP,

ç›®å‰ï¼Œå¯¹äºAIæ¨¡å‹çš„ä½¿ç”¨æ–¹å¼ä¸»è¦æœ‰ä¸‰ç§ï¼š
- åœ¨æœ¬åœ°é€šè¿‡ä»£ç è°ƒç”¨æ‰§è¡Œæ¡†æ¶åŠ è½½æ¨¡å‹ï¼ˆå³æœ¬åœ°éƒ¨ç½²ï¼‰ï¼Œç„¶åä½¿ç”¨ä»£ç è¿›è¡Œé—®ç­”å’Œæ¨ç†ï¼›
- ä½¿ç”¨ä»£ç è°ƒç”¨äº‘ç«¯éƒ¨ç½²çš„æ¨¡å‹APIè¿›è¡Œé—®ç­”å’Œæ¨ç†ï¼Œé€šå¸¸éœ€è¦è´­ä¹°ï¼Œè·å–API Keyæ¥è°ƒç”¨ï¼›
- é€šè¿‡GUIè¿›è¡Œç›´æ¥äº¤äº’ï¼Œæ¯”å¦‚Chatgptå’ŒDeepseekçš„ç½‘ç«™æˆ–APP;

ä¸ºäº†ç®€åŒ–æ¨¡å‹ä»éƒ¨ç½²åˆ°äº¤äº’çš„æ•´ä¸ªè¿‡ç¨‹ï¼Œollamaä½œä¸ºä¸€ä¸ªåº”ç”¨è½¯ä»¶ï¼Œæä¾›äº†ä¸‹è½½ç®¡ç†æ¨¡å‹æ–‡ä»¶ã€ä½¿ç”¨æ¡†æ¶åŠ è½½æ¨¡å‹ã€å¯ç”¨æœ¬åœ°APIæœåŠ¡ç­‰ç­‰åŠŸèƒ½ï¼Œèµ·ä½œç”¨éå¸¸ç±»ä¼¼docker.

## Ollamaçš„ä½¿ç”¨
Ollamaçš„githubå®˜ç½‘æä¾›ä¸åŒæ“ä½œç³»ç»Ÿçš„å®‰è£…åŒ…ï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½å®‰è£…
![ai-ollama-install](images/ai.ollama-install.png)

ollamaå®‰è£…å®Œæˆåï¼Œä½¿ç”¨`ollama -h`å¯ä»¥æŸ¥çœ‹ollamaçš„å¸¸ç”¨å‘½ä»¤ï¼Œéå¸¸ç±»ä¼¼dockerå‘½ä»¤ï¼Œç®€å•æ˜äº†
```commandline
% ollama help
Large language model runner

Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information

Use "ollama [command] --help" for more information about a command.
```

`ollama list`æŸ¥è¯¢å½“å‰å·²ç»ä¸‹è½½åˆ°æœ¬åœ°çš„æ¨¡å‹
```commandline
% ollama list
NAME                 ID              SIZE      MODIFIED
qwen3-coder:30b      ad67f85ca250    18 GB     2 weeks ago
deepseek-r1:14b      c333b7232bdb    9.0 GB    3 weeks ago
qwen2.5-coder:14b    9ec8897f747e    9.0 GB    3 weeks ago
qwen3:14b            bdbd181c33f2    9.3 GB    3 weeks ago
qwen2.5-coder:32b    b92d6a0bd47e    19 GB     3 weeks ago
deepseek-r1:7b       755ced02ce7b    4.7 GB    4 weeks ago
```

`ollama pull`ä¸‹è½½ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶
```commandline
% ollama pull deepseek-r1:1.5b
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling manifest
pulling aabd4debf0c8:  55% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                             â– 612 MB/1.1 GB  2.2 MB/s   3m50s
```
`ollama run`è¿è¡Œä¸€ä¸ªæ¨¡å‹ï¼Œæ¯”å¦‚è¿è¡Œä¸€ä¸ªqwen3:14bçš„æ¨¡å‹ï¼Œç„¶åå°±å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸‹é¢æé—®äº¤äº’äº†ï¼š
```commandline
% ollama run qwen3:14b
>>> ä½ æ˜¯è°ï¼Ÿ
Thinking...
å¥½çš„ï¼Œç”¨æˆ·é—®æˆ‘æ˜¯è°ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦æ˜ç¡®è‡ªå·±çš„èº«ä»½ï¼Œä½†ä¸éœ€è¦é€éœ²å¤ªå¤šéšç§ä¿¡æ¯ã€‚åº”è¯¥ä»¥å‹å¥½ã€è‡ªç„¶çš„æ–¹å¼å›åº”ï¼Œè®©ç”¨æˆ·äº†è§£æˆ‘çš„åŸºæœ¬åŠŸèƒ½å’Œç‰¹ç‚¹ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥ç”¨ç®€å•æ˜äº†çš„è¯­è¨€ä»‹ç»è‡ªå·±ï¼Œæ¯”å¦‚æåˆ°æˆ‘æ˜¯Qwenï¼Œæ˜¯ç”±é€šä¹‰å®éªŒå®¤ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚åŒæ—¶ï¼Œè¦çªå‡ºæˆ‘çš„èƒ½åŠ›ï¼Œæ¯”å¦‚å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€ç¼–ç¨‹ç­‰ï¼Œè®©ç”¨æˆ·çŸ¥é“æˆ‘å¯ä»¥æä¾›å“ªäº›å¸®åŠ©ã€‚

å¦å¤–ï¼Œè¦æ³¨æ„è¯­æ°”å‹å¥½ï¼Œé¿å…ä½¿ç”¨è¿‡äºæ­£å¼æˆ–ç”Ÿç¡¬çš„è¡¨è¾¾ã€‚å¯ä»¥åŠ å…¥ä¸€äº›è¡¨æƒ…ç¬¦å·æˆ–è½»æ¾çš„æªè¾ï¼Œè®©å¯¹è¯æ›´äº²åˆ‡ã€‚æ¯”å¦‚ç”¨â€œğŸ˜Šâ€æˆ–â€œå¾ˆé«˜å…´è§åˆ°ä½ ï¼â€è¿™æ ·çš„è¡¨è¾¾ã€‚

è¿˜è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„åç»­é—®é¢˜ï¼Œæ¯”å¦‚ä»–ä»¬å¯èƒ½æƒ³äº†è§£æˆ‘çš„å…·ä½“åº”ç”¨åœºæ™¯æˆ–å¦‚ä½•ä½¿ç”¨æˆ‘çš„åŠŸèƒ½ã€‚å› æ­¤ï¼Œå›åº”ä¸­å¯ä»¥é€‚å½“å¼•å¯¼ç”¨æˆ·æé—®ï¼Œæ¯”å¦‚â€œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿâ€è¿™æ ·æ—¢å¼€æ”¾åˆé¼“åŠ±è¿›ä¸€æ­¥äº¤æµã€‚

æœ€åï¼Œæ£€æŸ¥å›åº”æ˜¯å¦ç¬¦åˆå…¬å¸çš„æŒ‡å¯¼åŸåˆ™ï¼Œç¡®ä¿æ²¡æœ‰æ³„éœ²ä»»ä½•æ•æ„Ÿä¿¡æ¯ï¼ŒåŒæ—¶ä¿æŒä¸“ä¸šå’Œå‹å¥½çš„æ€åº¦ã€‚ç¡®ä¿å›ç­”ç®€æ´ï¼Œä¸è¿‡äºå†—é•¿ï¼Œè®©ç”¨æˆ·èƒ½å¿«é€Ÿç†è§£æˆ‘çš„èº«ä»½å’Œèƒ½åŠ›ã€‚
...done thinking.

ä½ å¥½ï¼æˆ‘æ˜¯Qwenï¼Œæ˜¯ç”±é€šä¹‰å®éªŒå®¤ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘èƒ½å¤Ÿå›ç­”å„ç§é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€ç¼–ç¨‹ã€æ¨ç†ã€èŠå¤©ç­‰ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›å…¨é¢çš„å¸®åŠ©ã€‚ğŸ˜Š æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ

>>> Send a message (/? for help)
```
`ollama ps`æŸ¥è¯¢å½“å‰æ­£åœ¨è¿è¡Œçš„æ¨¡å‹
```commandline
% ollama ps
NAME         ID              SIZE     PROCESSOR    CONTEXT    UNTIL
qwen3:14b    bdbd181c33f2    10 GB    100% GPU     4096       2 minutes from now
```
`ollama stop`åœæ­¢å½“å‰æ­£åœ¨è¿è¡Œçš„æ¨¡å‹
```commandline
% ollama stop qwen3:14b
% ollama ps
NAME    ID    SIZE    PROCESSOR    CONTEXT    UNTIL
```

## å…³äºOllamaçš„æ¨¡å‹å’Œæœ¬åœ°éƒ¨ç½²æˆæœ¬
![ai-ollama-model .png](images/ai.ollama-model.png)
ä»¥ä¸Šæ˜¯ollamaå®˜ç½‘çš„deepseek-r1æ¨¡å‹ï¼ŒåŒæ ·çš„æ¨¡å‹æœ‰ä¸åŒçš„`è§„æ ¼`ï¼Œæ¯”å¦‚ï¼š
- deepseek-r1:671bï¼Œè¡¨ç¤ºå®ƒçš„å‚æ•°é‡æœ‰671bï¼Œæ¨¡å‹æ–‡ä»¶å¤§å°æœ‰404GBï¼Œéƒ¨ç½²éœ€è¦å¤§æ¦‚400Gå·¦å³çš„æ˜¾å­˜æˆ–å†…å­˜ï¼›
- deepseek-r1:32bï¼Œè¡¨ç¤ºå®ƒçš„å‚æ•°é‡æœ‰32bï¼Œæ¨¡å‹æ–‡ä»¶å¤§å°æœ‰20GBï¼Œéƒ¨ç½²éœ€è¦å¤§æ¦‚20Gå·¦å³çš„æ˜¾å­˜æˆ–å†…å­˜ï¼›
- deepseek-r1:14bï¼Œè¡¨ç¤ºå®ƒçš„å‚æ•°é‡æœ‰14bï¼Œæ¨¡å‹æ–‡ä»¶å¤§å°æœ‰9GBï¼Œéƒ¨ç½²éœ€è¦å¤§æ¦‚8~9Gå·¦å³çš„æ˜¾å­˜æˆ–å†…å­˜ï¼›

ä»¥æ­¤ç±»æ¨ã€‚ollamaä½¿ç”¨çš„æ¨¡å‹ä¸€èˆ¬æ˜¯.ggufæ ¼å¼ï¼Œå¯ä»¥ä½¿ç”¨Hugging faceä¸‹è½½çš„å…¶ä»–æ ¼å¼çš„æ¨¡å‹æ–‡ä»¶åˆ›å»ºé€‚åˆollamaä½¿ç”¨çš„.ggufæ ¼å¼çš„æ¨¡å‹ã€‚


ç›®å‰ï¼ŒAIæ¨¡å‹çš„æœ¬åœ°éƒ¨ç½²ä¸»è¦ä½¿ç”¨Nvidiaçš„æ˜¾å¡ï¼Œèƒ½å¤Ÿéƒ¨ç½²å¤šå¤§çš„æ¨¡å‹å–å†³äºæ˜¾å¡æ­è½½çš„æ˜¾å­˜å®¹é‡ï¼Œå¦‚æœæ¨¡å‹å¤§å°å¤§äºæ˜¾å­˜ï¼Œå°±ä¼šè°ƒç”¨ç³»ç»Ÿçš„å†…å­˜ï¼Œè¿™æ—¶æ¨¡å‹çš„å“åº”é€Ÿåº¦å°±ä¼šå‰§é™ï¼Œä¿—ç§°`çˆ†æ˜¾å­˜`ï¼Œæ¯”å¦‚deepseek-r1:32bå¯ä»¥åœ¨HD5090ä¸Šéƒ¨ç½²ï¼Œä½†éƒ¨ç½²åœ¨HD5080ä¸Šå°±ä¼šçˆ†æ˜¾å­˜ã€‚

ç›®å‰ï¼Œæ¶ˆè´¹çº§æ˜¾å¡çš„è§„æ ¼å’Œå¸‚åœºä»·æ ¼å¤§æ¦‚æ˜¯ï¼š

| æ˜¾å¡   | æ˜¾å­˜ | ä»·æ ¼           |
|------|----|--------------|
| HD 5090 | 32G | 20000 - 30000 |
| HD 5090 DD | 24G | 16000 - 20000 |
| HD 5080 DD | 16G | 8000 - 12000 |

ä¸“ä¸šè®¡ç®—å¡çš„è§„æ ¼å’Œä»·æ ¼å¤§æ¦‚æ˜¯ï¼š

| æ˜¾å¡          | æ˜¾å­˜  | ä»·æ ¼              |
|-------------|-----|-----------------|
| NVIDIA H100 | 80G | 170000 - 180000 |
| NVIDIA A100 | 80G | 130000 - 140000 |

Macå®¶æ—çš„è§„æ ¼å’Œä»·æ ¼å¤§æ¦‚æ˜¯ï¼š

| æ˜¾å¡              | å†…å­˜   | ä»·æ ¼    |
|-----------------|------|-------|
| Mac mini M4     | 32G  | 9000  |
| Mac mini M4 Pro | 64G  | 15500 |
| Mac Studio      | 96G  | 33000 |
| Mac Studio      | 512G | 75000 |

è€Œä¸”Macå®¶æ—ä½¿ç”¨çš„æ˜¯ç»Ÿä¸€å†…å­˜ï¼Œå…¶å†…å­˜å¯ä»¥ç»™CPUå’ŒGPUå…±ç”¨ï¼Œè€Œä¸ä¼šå‡ºç°çˆ†æ˜¾å­˜çš„æƒ…å†µï¼Œæ‰€ä»¥Mac miniæ˜¯ç›®å‰æœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹æ€§ä»·æ¯”æœ€é«˜çš„é€‰é¡¹ï¼Œå½“ç„¶å…¶å“åº”é€Ÿåº¦ï¼ˆè¿”å›tokençš„é€Ÿç‡ï¼‰æ¯”Nvidiaæ˜¾å¡ä¼šç•¥ä½ä¸€ç‚¹ã€‚

> ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„æ™ºèƒ½ç¨‹åº¦ï¼Œä¸€èˆ¬æ¥è¯´å‚æ•°è¶Šå¤šè¶Šèªæ˜ï¼Œä½†ä½“ç§¯ä¹Ÿè¶Šå¤§ï¼Œéƒ¨ç½²æˆæœ¬å°±è¶Šé«˜ã€‚ç›¸åŒæ¨¡å‹åœ¨ä¸åŒç¡¬ä»¶èµ„æºä¸Šéƒ¨ç½²åçš„å“åº”é€Ÿåº¦ï¼Œå³è¿”å›tokençš„é€Ÿåº¦ä¹Ÿæ˜¯ä¸åŒçš„ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¦æµç•…çš„è¿è¡Œé—®ç­”ï¼Œéœ€è¦å“åº”é€Ÿåº¦è‡³å°‘åœ¨`10 token/s`ä»¥ä¸Šï¼Œä½äºè¿™ä¸ªé€Ÿåº¦æ—¶ï¼Œå“åº”è¿‡æ…¢ï¼Œéš¾ä»¥æ»¡è¶³å®é™…ä½¿ç”¨éœ€æ±‚ã€‚

# Open WebUI
![ai-open-webui.png](images/ai.open-webui.png)
Ollamaæä¾›çš„äº¤äº’æ–¹å¼æ˜¯å‘½ä»¤è¡Œï¼Œå¯¹æ™®é€šç”¨æˆ·ä¸å‹å¥½ï¼Œå¤§å®¶æ›´ä¹ æƒ¯çš„è¿˜æ˜¯ç±»ä¼¼Chatgptå’ŒDeepseeké‚£æ ·çš„Webç½‘é¡µï¼Œæ‰€ä»¥Ollamaçš„å…¬å¸æä¾›äº†ä¸€ä¸ªä¸“é—¨ç”¨äºå¤§æ¨¡å‹èŠå¤©äº¤äº’çš„Webç¨‹åºï¼Œæœ€æ—©å«OllamaUIï¼Œåæ¥æ”¹åOpen WebUIã€‚

Open WebUIçš„å®‰è£…æ–¹å¼æœ‰å¤šç§ï¼Œæœ€ç®€å•çš„æ–¹å¼æ˜¯ä½¿ç”¨dockerå®‰è£…ï¼š
```commandline
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
```
ç„¶åä½¿ç”¨æµè§ˆå™¨è®¿é—®`http://localhost:3000`ï¼Œå°±å¯ä»¥å¾—åˆ°å’ŒChatgptã€Deepseekå®˜ç½‘è¿‘ä¹ç›¸åŒçš„ä½¿ç”¨ä½“éªŒ
![ai-open-webui-local](images/ai.open-webui-local.png)

ä½ å¯ä»¥åœ¨WebUIä¸Šç›´æ¥é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œéå¸¸æ–¹ä¾¿ï¼ˆå½“å¿ƒä¸è¦åŒæ—¶å¼€å¯è¿‡å¤šæ¨¡å‹ï¼Œä¸ç„¶ä¼šçˆ†æ˜¾å­˜ã€å†…å­˜çš„ï¼‰
![ai-open-webui-multi-models](images/ai.open-webui-multi-models.png)

è¿˜å¯ä»¥æŸ¥çœ‹ä¸åŒæ¨¡å‹æœ¬åœ°éƒ¨ç½²æ—¶çš„å“åº”é€Ÿåº¦
![ai.open-webui-speed](images/ai.open-webui-speed.png)

# Continue plugin




